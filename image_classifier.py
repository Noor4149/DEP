# -*- coding: utf-8 -*-
"""Image Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1--ml_aRLfYI4f2V2MV0GW6i6KggKAjRA
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

# installing tensorflow

!pip install tensorflow

import tensorflow as tf

from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical

from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print(f"x_train shape: {x_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"x_test shape: {x_test.shape}")
print(f"y_test shape: {y_test.shape}")

data = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

data[0:10]

#dimensions:
width = 10
length = 10

fig, axes = plt.subplots(length, width, figsize = (25,25))     #plots the axis frames
axes = axes.ravel()  #flattens 2D into 1D
n = len(x_train)

for i in np.arange(0, width * length):

    index = np.random.randint(0, n)    #random sampling
    axes[i].imshow(x_train[index,1:])     #takes the image and displays at the selected index
    label_index = int(y_train[index])     #gets the label index
    axes[i].set_title(data[label_index], fontsize = 10)       # sets the title of the image shown
    axes[i].axis('off')

labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

classes, counts = np.unique(y_train, return_counts=True)
plt.barh(labels, counts, color = 'lightskyblue')
plt.title("Class Distribution Plot [Training Set]")

classes, counts = np.unique(y_test, return_counts=True)
plt.barh(labels, counts, color = 'lightskyblue')
plt.title('Class distribution in [Testing set]')

# Data Pre- processing

Xr = x_train/255          # where 255 is the pixel value
Xt = x_test/255

yr_cat = to_categorical(y_train, 10)
yt_cat = to_categorical(y_test, 10)

yr_cat

yt_cat

# Model Building

# Shape of CIFAR-10 is 32*32 for 10 classes so,
img_sp = (32, 32,3)
size = (3, 3)
model = Sequential()
model.add(Conv2D(32, size, activation = 'relu', input_shape = img_sp, padding = 'same'))
model.add(BatchNormalization())
model.add(Conv2D(32, size, activation = 'relu', input_shape = img_sp, padding = 'same'))
model.add(BatchNormalization())

model.add(MaxPool2D(pool_size = (2, 2)))

model.add(Dropout(0.2))

model.add(Conv2D(64, size, activation = 'relu', input_shape = img_sp, padding = 'same'))
model.add(BatchNormalization())
model.add(Conv2D(64, size, activation = 'relu', input_shape = img_sp, padding = 'same'))
model.add(BatchNormalization())

model.add(MaxPool2D(pool_size = (2, 2)))
model.add(Dropout(0.2))

model.add(Flatten())
model.add(Dense(128, activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(10, activation = 'softmax'))

metric = ['accuracy', tf.keras.metrics.Precision(name = 'precision'), tf.keras.metrics.Recall(name = 'recall')]
model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = metric)

model.summary()

estp = EarlyStopping(monitor = 'val_loss', patience = 2)

#data augumentation

batch = 32
datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True)
traingen = datagen.flow(Xr, yr_cat, batch_size = batch)
steps = Xr.shape[0] // batch
gen = model.fit(traingen, epochs = 10, validation_data = (Xt, yt_cat)) # verbose = 1, steps_per_epoch = steps, callbacks = [estp])

# Model Evaluation

plt.figure(figsize = (12, 15))

plt.subplot(4, 2, 1)
plt.plot(gen.history['loss'], label = 'Training Loss')
plt.plot(gen.history['val_loss'], label = 'Validation Loss')
plt.title('Loss')
plt.legend()

plt.subplot(4, 2, 2)
plt.plot(gen.history['accuracy'], label = 'Training Accuracy')
plt.plot(gen.history['val_accuracy'], label = 'Validation Accuracy')
plt.title('Accuracy')
plt.legend()

plt.subplot(4, 2, 3)
plt.plot(gen.history['recall'], label = 'Training Recall')
plt.plot(gen.history['val_recall'], label = 'Validation Recall')
plt.title('Recall')
plt.legend()

plt.subplot(4, 2, 4)
plt.plot(gen.history['precision'], label = 'Training Precision')
plt.plot(gen.history['val_precision'], label = 'Validation Precision')
plt.title('Precision')
plt.legend()

evl = model.evaluate(Xt, yt_cat)
print(f'Test Accuracy : {evl[1] * 100:.2f}%')

y_pred = model.predict(Xt)
y_pred = np.argmax(y_pred, axis = 1)

con_mat = confusion_matrix(y_test, y_pred)

show = ConfusionMatrixDisplay(con_mat, display_labels = labels)
#show.plot(cmap = 'Blues')
fig, ax = plt.subplots(figsize=(12, 15))
show = show.plot(xticks_rotation='vertical', ax=ax,cmap='Blues')

print(classification_report(y_test, y_pred, target_names = labels))

# Testing The Model:

test_img = x_test[4]
plt.imshow(test_img)

print(f"Image is: {y_test[4]}")

pred = np.argmax(model.predict(test_img.reshape(1, 32, 32, 3)))

data